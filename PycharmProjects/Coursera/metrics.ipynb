{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 59 34 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('classification.csv', delim_whitespace=False)\n",
    "new_data = data.as_matrix()\n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "for line in new_data:\n",
    "    if line[0] == 1:\n",
    "        if line[1] == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    else:\n",
    "        if line[1] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "print(TP, FP, FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n0.56\n0.42\n0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "score = [accuracy_score(data['true'], data['pred']), precision_score(data['true'], data['pred']), \n",
    "         recall_score(data['true'], data['pred']), f1_score(data['true'], data['pred'])]\n",
    "for item in score:\n",
    "    print(round(item, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71918767507002801, 0.70868347338935567, 0.63515406162464982, 0.69192677070828335]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score_data = pd.read_csv('scores.csv', delim_whitespace=False, index_col='true')\n",
    "score = [roc_auc_score(score_data.index, score_data['score_logreg']), roc_auc_score(score_data.index, score_data['score_svm']),\n",
    "         roc_auc_score(score_data.index, score_data['score_knn']), roc_auc_score(score_data.index, score_data['score_tree'])]\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score_knn': 0.60655737704918034, 'score_logreg': 0.63025210084033612, 'score_svm': 0.6228070175438597, 'score_tree': 0.6517857142857143}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "max_score = {}\n",
    "for label in score_data:\n",
    "    precision, recall, thresholds = precision_recall_curve(score_data.index, score_data[label])\n",
    "    max_score[label] = 0\n",
    "    for i in range(len(thresholds)):\n",
    "        if recall[i] > 0.7 and precision[i] > max_score[label]:\n",
    "            max_score[label] = precision[i]\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}